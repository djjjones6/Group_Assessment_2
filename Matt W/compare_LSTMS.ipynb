{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train_data.pickle', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/test_data.pickle', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(df,N, window_size):\n",
    "        \n",
    "    X_sequences = [df.iloc[i:i+window_size].values for i in range(N - window_size)]\n",
    "    Y_values = [df.iloc[i+window_size]['pollution'] for i in range(N - window_size)]\n",
    "\n",
    "    return np.array(X_sequences).astype('float64'), np.array(Y_values).astype('float64').reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "N= len(train_data)\n",
    "X_train, y_train = generate_sequence(train_data,N, window_size)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "M=len(test_data)\n",
    "X_test, y_test = generate_sequence(test_data,M,window_size)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]\n",
    "n_outputs = y_train.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from numpy import concatenate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import ConvLSTM2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(7)\n",
    "MV_LSTM = Sequential()\n",
    "MV_LSTM.add(Input(shape =(n_steps, n_features)))\n",
    "MV_LSTM.add(LSTM(32,return_sequences=True))\n",
    "MV_LSTM.add(Dropout(0.1)) #Prevent overfitting\n",
    "MV_LSTM.add(LSTM(16, return_sequences=False))\n",
    "MV_LSTM.add(Dense(n_outputs, activation ='linear')) \n",
    "\n",
    "MV_LSTM.compile(optimizer=Adam(learning_rate = 0.001), loss='mse', metrics = [RootMeanSquaredError()])\n",
    "\n",
    "# Save the initial weights of the model right after it is defined and compiled\n",
    "initial_weights = MV_LSTM.get_weights()\n",
    "\n",
    "MV_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    #Reset weights\n",
    "    MV_LSTM.set_weights(initial_weights)\n",
    "    MV_LSTM.fit(X_train, y_train, epochs=20, validation_split=0.1, batch_size=100,shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
